{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import graphlab as gl\n",
    "import numpy as np\n",
    "import math\n",
    "from operator import itemgetter\n",
    "from IPython.core.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to rahultyagirt7@outlook.com and will expire on June 03, 2017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: /tmp/graphlab_server_1487145440.log\n"
     ]
    }
   ],
   "source": [
    "# Loading user data and modifying it to work with Regression based model\n",
    "user_data = gl.load_sframe(\"./user_data_clean/\")\n",
    "# remove rows where country is not mentioned in location\n",
    "fil = []\n",
    "for item in user_data[\"location\"]:\n",
    "    temp = item.split(\",\")\n",
    "    if len(temp) <= 2 or temp[2] == \"\":\n",
    "        fil.append(False)\n",
    "    else:\n",
    "        fil.append(True)\n",
    "fil = gl.SArray(data=fil)\n",
    "\n",
    "user_data = user_data[fil]\n",
    "\n",
    "# locations where city is not mentioned replace states with name of their country rather than excluding them\n",
    "# and convert a complete string of location to a list of strings containg city name and country name as elements\n",
    "def modify(st):\n",
    "    st = st.split(\",\")\n",
    "    if st[1] == \" \" or st[1] == \" n/a\":\n",
    "        st[1] = st[2]\n",
    "    del(st[0])\n",
    "    st_0 = st[0].strip() \n",
    "    st_1 = st[1].strip()\n",
    "    return st_0 + \", \" + st_1\n",
    "\n",
    "user_data[\"location\"] = user_data[\"location\"].apply(modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"1560975296,\"Krazy &amp; Ignatz 1929-1930: \\\"\"A Mice, A Brick, A Lovely Night\\\"\" (Krazy Kat)\",George Herriman,2003,Fantagraphics Books,http://images.amazon.com/images/P/1560975296.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/1560975296.01.MZZZZZZZ.jpg,...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"1560975296,\"Krazy &amp; Ignatz 1929-1930: \\\"\"A Mice, A Brick, A Lovely Night\\\"\" (Krazy Kat)\",George Herriman,2003,Fantagraphics Books,http://images.amazon.com/images/P/1560975296.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/1560975296.01.MZZZZZZZ.jpg,...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"30131766,\"\\\"\"What Do We Have for the Witnesses, Johnnie?\\\"\" (A Doonesbury book)\",\"G. B., Trudeau\",1980,Henry Holt &amp, Co,http://images.amazon.com/images/P/0030131766.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/0030131766.01.MZZZZZZZ.jpg,http://imag...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"30131766,\"\\\"\"What Do We Have for the Witnesses, Johnnie?\\\"\" (A Doonesbury book)\",\"G. B., Trudeau\",1980,Henry Holt &amp, Co,http://images.amazon.com/images/P/0030131766.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/0030131766.01.MZZZZZZZ.jpg,http://imag...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"809235285,\"\\\"\"If the Other Guy Isn't Jack Nicholson, I'Ve Got the Part\\\"\": Hollywood Tales of Big Breaks, Bad Luck, and Box-Office Magic\",Ron Base,1994,McGraw-Hill/Contemporary Books,http://images.amazon.com/images/P/0809235285.01.THUMBZZZ.jpg,http://image...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"809235285,\"\\\"\"If the Other Guy Isn't Jack Nicholson, I'Ve Got the Part\\\"\": Hollywood Tales of Big Breaks, Bad Luck, and Box-Office Magic\",Ron Base,1994,McGraw-Hill/Contemporary Books,http://images.amazon.com/images/P/0809235285.01.THUMBZZZ.jpg,http://image...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"907083149X,Contemporary poetry of the low countries,Hugo Brems,1993,\"Flemish-Netherlands Foundation \\\"\"Stichting Ons Erfdeel,\\\"\";\"\"http://images.amazon.com/images/P/907083149X.01.THUMBZZZ.jpg\",http://images.amazon.com/images/P/907083149X.01.MZZZZZZZ.jpg,ht...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"907083149X,Contemporary poetry of the low countries,Hugo Brems,1993,\"Flemish-Netherlands Foundation \\\"\"Stichting Ons Erfdeel,\\\"\";\"\"http://images.amazon.com/images/P/907083149X.01.THUMBZZZ.jpg\",http://images.amazon.com/images/P/907083149X.01.MZZZZZZZ.jpg,ht...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"449208028,\"\\\"\"I Ain't Much, Baby-But I'm All I'Ve Got\\\"\";\"\"Jess, Ph. D. Lair\",1990,Fawcett Books,http://images.amazon.com/images/P/0449208028.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/0449208028.01.MZZZZZZZ.jpg,http://images.amazon.com/images/P/044...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"449208028,\"\\\"\"I Ain't Much, Baby-But I'm All I'Ve Got\\\"\";\"\"Jess, Ph. D. Lair\",1990,Fawcett Books,http://images.amazon.com/images/P/0449208028.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/0449208028.01.MZZZZZZZ.jpg,http://images.amazon.com/images/P/044...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"1885222971,\"The Lion King: The Pal Patrol (Disney's \\\"\"Storytime Treasures\\\"\" Library, Volume 1)\",Inc. Staff Disney Enterprises,1997,Advance Publishers LLC,http://images.amazon.com/images/P/1885222971.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/18852...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"1885222971,\"The Lion King: The Pal Patrol (Disney's \\\"\"Storytime Treasures\\\"\" Library, Volume 1)\",Inc. Staff Disney Enterprises,1997,Advance Publishers LLC,http://images.amazon.com/images/P/1885222971.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/18852...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"671026437,\"The Memory Cure : \\\"\"The Safe, Scientific Breakthrough that Can Slow, Halt, or Even ReversesAge-Related Memory Loss\\\"\";\"\"Thomas Crook\",1999,Pocket,http://images.amazon.com/images/P/0671026437.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/067...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"671026437,\"The Memory Cure : \\\"\"The Safe, Scientific Breakthrough that Can Slow, Halt, or Even ReversesAge-Related Memory Loss\\\"\";\"\"Thomas Crook\",1999,Pocket,http://images.amazon.com/images/P/0671026437.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/067...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"378460529X,\"Hundert Gedichte: Eine Auswahl aus den Büchern \\\"\"Landaufenthalt,\\\"\" \\\"\"Zaubersprüche,\\\"\" \\\"\"Rückenwind,\\\"\" \\\"\"Drachensteigen,\\\"\" und ein Gespräch über ihre Gedichte (Textura)\",Sarah Kirsch,1985,Langewiesche-Brandt,http://images.amazon.com...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"378460529X,\"Hundert Gedichte: Eine Auswahl aus den Büchern \\\"\"Landaufenthalt,\\\"\" \\\"\"Zaubersprüche,\\\"\" \\\"\"Rückenwind,\\\"\" \\\"\"Drachensteigen,\\\"\" und ein Gespräch über ihre Gedichte (Textura)\",Sarah Kirsch,1985,Langewiesche-Brandt,http://images.amazon.com...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"312980469,\"\\\"\"If I Die...\\\"\" : A True Story of Obsessive Love, Uncontrollable Greed, and Murder (St. Martin's True Crime Library)\",Michael Fleeman,2002,St. Martin's True Crime,http://images.amazon.com/images/P/0312980469.01.THUMBZZZ.jpg,http://images.amazo...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"312980469,\"\\\"\"If I Die...\\\"\" : A True Story of Obsessive Love, Uncontrollable Greed, and Murder (St. Martin's True Crime Library)\",Michael Fleeman,2002,St. Martin's True Crime,http://images.amazon.com/images/P/0312980469.01.THUMBZZZ.jpg,http://images.amazo...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"553346687,\"\\\"\"Surely You're Joking, Mr. Feynman!\\\"\": Adventures of a Curious Character\",Richard P. Feynman,1990,Bantam Books,http://images.amazon.com/images/P/0553346687.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/0553346687.01.MZZZZZZZ.jpg,http://im...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"553346687,\"\\\"\"Surely You're Joking, Mr. Feynman!\\\"\": Adventures of a Curious Character\",Richard P. Feynman,1990,Bantam Books,http://images.amazon.com/images/P/0553346687.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/0553346687.01.MZZZZZZZ.jpg,http://im...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>60 lines failed to parse correctly</pre>"
      ],
      "text/plain": [
       "60 lines failed to parse correctly"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /media/a/New Volume/Course materials/Project/BX-CSV-Dump/csv_files/BX-Books.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /media/a/New Volume/Course materials/Project/BX-CSV-Dump/csv_files/BX-Books.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 4.54519 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 4.54519 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,int,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"078625050X,Windowpane (Five Star First Edition Science Fiction &amp, Fantasy),Steve Perry,2003,Five Star (ME),http://images.amazon.com/images/P/078625050X.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/078625050X.01.MZZZZZZZ.jpg,http://images.amazon.com...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"078625050X,Windowpane (Five Star First Edition Science Fiction &amp, Fantasy),Steve Perry,2003,Five Star (ME),http://images.amazon.com/images/P/078625050X.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/078625050X.01.MZZZZZZZ.jpg,http://images.amazon.com...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"1564404633,Southern Spain Andalucia &amp, Gibraltar (Cadogan Guides),Dana Facaros,1994,Globe Pequot Pr,http://images.amazon.com/images/P/1564404633.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/1564404633.01.MZZZZZZZ.jpg,http://images.amazon.com/images...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"1564404633,Southern Spain Andalucia &amp, Gibraltar (Cadogan Guides),Dana Facaros,1994,Globe Pequot Pr,http://images.amazon.com/images/P/1564404633.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/1564404633.01.MZZZZZZZ.jpg,http://images.amazon.com/images...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"3803101034,Liebesgedichte (Quartheft , 103),Erich Fried,1979,K. Wagenbach,http://images.amazon.com/images/P/3803101034.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/3803101034.01.MZZZZZZZ.jpg,http://images.amazon.com/images/P/3803101034.01.LZZZZZZZ.jpg...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"3803101034,Liebesgedichte (Quartheft , 103),Erich Fried,1979,K. Wagenbach,http://images.amazon.com/images/P/3803101034.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/3803101034.01.MZZZZZZZ.jpg,http://images.amazon.com/images/P/3803101034.01.LZZZZZZZ.jpg...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"671027360,Angels &amp, Demons,Dan Brown,2001,Pocket Star,http://images.amazon.com/images/P/0671027360.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/0671027360.01.MZZZZZZZ.jpg,http://images.amazon.com/images/P/0671027360.01.LZZZZZZZ.jpg,,,,,\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"671027360,Angels &amp, Demons,Dan Brown,2001,Pocket Star,http://images.amazon.com/images/P/0671027360.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/0671027360.01.MZZZZZZZ.jpg,http://images.amazon.com/images/P/0671027360.01.LZZZZZZZ.jpg,,,,,\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"312872682,The James Dean Affair: A Neil Gulliver &amp, Stevie Marriner Novel,Robert S. Levinson,2000,St Martins Pr,http://images.amazon.com/images/P/0312872682.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/0312872682.01.MZZZZZZZ.jpg,http://images.amazo...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"312872682,The James Dean Affair: A Neil Gulliver &amp, Stevie Marriner Novel,Robert S. Levinson,2000,St Martins Pr,http://images.amazon.com/images/P/0312872682.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/0312872682.01.MZZZZZZZ.jpg,http://images.amazo...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"1590580508,Prairie Gothic: A Mad Dog &amp, English Man Mystery,J.M. Hayes,2003,Poisoned Pen Press,http://images.amazon.com/images/P/1590580508.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/1590580508.01.MZZZZZZZ.jpg,http://images.amazon.com/images/P/15...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"1590580508,Prairie Gothic: A Mad Dog &amp, English Man Mystery,J.M. Hayes,2003,Poisoned Pen Press,http://images.amazon.com/images/P/1590580508.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/1590580508.01.MZZZZZZZ.jpg,http://images.amazon.com/images/P/15...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"743486226,Angels &amp, Demons,Dan Brown,2003,Atria,http://images.amazon.com/images/P/0743486226.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/0743486226.01.MZZZZZZZ.jpg,http://images.amazon.com/images/P/0743486226.01.LZZZZZZZ.jpg,,,,,\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"743486226,Angels &amp, Demons,Dan Brown,2003,Atria,http://images.amazon.com/images/P/0743486226.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/0743486226.01.MZZZZZZZ.jpg,http://images.amazon.com/images/P/0743486226.01.LZZZZZZZ.jpg,,,,,\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"679751343,Angels &amp, Insects : Two Novellas,A.S. BYATT,1994,Vintage,http://images.amazon.com/images/P/0679751343.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/0679751343.01.MZZZZZZZ.jpg,http://images.amazon.com/images/P/0679751343.01.LZZZZZZZ.jpg,,,,...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"679751343,Angels &amp, Insects : Two Novellas,A.S. BYATT,1994,Vintage,http://images.amazon.com/images/P/0679751343.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/0679751343.01.MZZZZZZZ.jpg,http://images.amazon.com/images/P/0679751343.01.LZZZZZZZ.jpg,,,,...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"373257171,Last Man In Montana (Boots &amp, Booties) (Harlequin Temptation),Kristine Rolofson,1996,Harlequin,http://images.amazon.com/images/P/0373257171.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/0373257171.01.MZZZZZZZ.jpg,http://images.amazon.com/i...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"373257171,Last Man In Montana (Boots &amp, Booties) (Harlequin Temptation),Kristine Rolofson,1996,Harlequin,http://images.amazon.com/images/P/0373257171.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/0373257171.01.MZZZZZZZ.jpg,http://images.amazon.com/i...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"340424267X,In dunklen Tiefen. 2 Romane in einem Band: Das Weltraumtor, Sie kamen von den Sternen.,Marion Zimmer Bradley,2000,L�?¼bbe,http://images.amazon.com/images/P/340424267X.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/340424267X.01.MZZZZZZZ.jp...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"340424267X,In dunklen Tiefen. 2 Romane in einem Band: Das Weltraumtor, Sie kamen von den Sternen.,Marion Zimmer Bradley,2000,L�?¼bbe,http://images.amazon.com/images/P/340424267X.01.THUMBZZZ.jpg,http://images.amazon.com/images/P/340424267X.01.MZZZZZZZ.jp...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 188097 lines. Lines per second: 47790.2</pre>"
      ],
      "text/plain": [
       "Read 188097 lines. Lines per second: 47790.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>4724 lines failed to parse correctly</pre>"
      ],
      "text/plain": [
       "4724 lines failed to parse correctly"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /media/a/New Volume/Course materials/Project/BX-CSV-Dump/csv_files/BX-Books.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /media/a/New Volume/Course materials/Project/BX-CSV-Dump/csv_files/BX-Books.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 266655 lines in 4.62438 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 266655 lines in 4.62438 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading required data\n",
    "book_data = gl.SFrame(\"./csv_files/BX-Books.csv\")\n",
    "book_data = book_data.rename({\"ISBN\":\"book_id\", \"Book-Title\":\"title\", \"Book-Author\":\"author\", \"Year-Of-Publication\":\"year\",\n",
    "                      \"Publisher\":\"publisher\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /media/a/New Volume/Course materials/Project/BX-CSV-Dump/csv_files/BX-Book-Ratings.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /media/a/New Volume/Course materials/Project/BX-CSV-Dump/csv_files/BX-Book-Ratings.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 3.63089 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 3.63089 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[int,str,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /media/a/New Volume/Course materials/Project/BX-CSV-Dump/csv_files/BX-Book-Ratings.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /media/a/New Volume/Course materials/Project/BX-CSV-Dump/csv_files/BX-Book-Ratings.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1149780 lines in 2.4786 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1149780 lines in 2.4786 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "book_ratings_data = gl.SFrame.read_csv(\"./csv_files/BX-Book-Ratings.csv\", delimiter=\";\")\n",
    "book_ratings_data.rename({\"User-ID\":\"user_id\", \"ISBN\":\"book_id\", \"Book-Rating\":\"ratings\"})\n",
    "\n",
    "#following four lines of code extract users at random who has rated books greater than 8(high rating) \n",
    "high_rated_data = book_ratings_data[book_ratings_data[\"ratings\"] >= 8]\n",
    "low_rated_data = book_ratings_data[book_ratings_data[\"ratings\"] < 8]\n",
    "train_data_1, test_data = gl.recommender.util.random_split_by_user(high_rated_data, \n",
    "                                                                         user_id=\"user_id\", item_id=\"book_id\")\n",
    "train_data = train_data_1.append(low_rated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PopularityModel:\n",
    "    \n",
    "    most_popular_books_ids = []\n",
    "    most_popular_books = []\n",
    "    \n",
    "    \"\"\"\n",
    "    Function that will take ratings data as argument. It first select books rated 10 from range 0-10 and \n",
    "    then count the number of books rated maximum times. After sorting books according to their counts, it checks\n",
    "    if the book id is present in book data, if it do then it appends that book and its id to respective lists.\n",
    "    \"\"\"\n",
    "    def predict(self, train_data=None, n=2, user_id=\"user_id\", item_id=\"item_id\", \n",
    "                              user_data=None, item_data=None, rating=\"rating\"):\n",
    "        \n",
    "        # Count how many times a book is rated 10 and sort in descending order\n",
    "        rating_10 = train_data[train_data[rating] == 10]\n",
    "        popular_books = rating_10.groupby(key_columns=item_id, \n",
    "                                              operations={\"count\": gl.aggregate.COUNT()})\n",
    "        popular_books = popular_books.sort(\"count\", ascending=False)\n",
    "    \n",
    "        pos_list = [] \n",
    "        for i in range(len(item_data[item_id])):\n",
    "            if len(pos_list) == 5: break\n",
    "            if popular_books[item_id][i] in item_data[item_id]:\n",
    "                pos_list.append(i)\n",
    "        \n",
    "        for pos in pos_list:\n",
    "            self.most_popular_books_ids.append(popular_books[item_id][pos])\n",
    "        for ids in self.most_popular_books_ids:\n",
    "            self.most_popular_books.append(item_data[item_data[item_id] == ids][[\"title\", \n",
    "                                                            \"author\", \"year\", \"publisher\"]][0])\n",
    "        return self.most_popular_books[0:n], self.most_popular_books_ids[0:n]\n",
    "    \n",
    "class RegressionModel:\n",
    "    \n",
    "    \"\"\"\n",
    "    This funciton takes as argument user's age and location(consisting state) and outputs two lists one containing ids\n",
    "    of recommended books and other list contains title of recommended books. Currently, it only choose a movie among \n",
    "    3000 movies randomly chosen from IMPLICIT test dataset having total count of 45000 movies .(Note that model was \n",
    "    trained on explicit dataset which is different from implicit dataset).\n",
    "    Count of movies can be increased(by modifiying max variable) if required to search among more movies, but it will take \n",
    "    considerable time depending on the machine this function is evaluated upon.\n",
    "    \"\"\"\n",
    "    def predict(self, location, age, search_over, n=3):\n",
    "        # Load required models and data\n",
    "        regression_model = gl.load_model(\"./regression_model_file/\")\n",
    "        book_data = gl.load_sframe(\"./book_data_clean/\")\n",
    "        implicit_data = gl.load_sframe(\"./implicit_rating_data/\")\n",
    "        book_data.filter_by(implicit_data[\"book_id\"], \"book_id\")\n",
    "        \n",
    "        # Select approx (search_over) books by splitting data RANDOMLY\n",
    "        split = search_over/45000.0\n",
    "        book_data, other_data = book_data.random_split(split)\n",
    "        \n",
    "        predicted_ratings = []\n",
    "        count = 0\n",
    "        for book in book_data:\n",
    "            if count == search_over:\n",
    "                break\n",
    "            count += 1\n",
    "            book[\"location\"] = location\n",
    "            book[\"age\"] = age\n",
    "            rating = regression_model.predict(book)[0]\n",
    "            if rating >= 8.0:\n",
    "                predicted_ratings.append((book[\"book_id\"], rating))\n",
    "    \n",
    "        predicted_ratings = sorted(predicted_ratings, key=itemgetter(1), reverse=True)\n",
    "\n",
    "        # Recommeded books in decresing values of ratings\n",
    "        recommended_books_id = []\n",
    "        for i in range(5):\n",
    "            recommended_books_id.append(predicted_ratings[i][0])\n",
    "\n",
    "        recommended_books = []\n",
    "        for book in recommended_books_id:\n",
    "            for item in book_data:\n",
    "                if book in item[\"book_id\"]:\n",
    "                    del(item[\"book_id\"])\n",
    "                    recommended_books.append(item)\n",
    "                    break\n",
    "        return recommended_books[0:n], recommended_books_id[0:n]\n",
    "    \n",
    "class SimilarityModel:\n",
    "    \n",
    "    # Returns a distance based similarity score based for user1 and user2\n",
    "    # Score between (0-1) score 1 means distance zero, higher the score more similar the users are\n",
    "    def euclid(self, ratings, user1, user2):\n",
    "        flag = 0\n",
    "        for item in ratings[user1]:\n",
    "            if item in ratings[user2]:\n",
    "                flag = 1; break\n",
    "            \n",
    "        # if no ratings in common, return 0\n",
    "        if flag == 0: return 0\n",
    "    \n",
    "        # Add up the squares of all differences\n",
    "        sum_squares = sum([pow(ratings[user1][item]-ratings[user2][item],2) \n",
    "                       for item in ratings[user1] if item in ratings[user2]])\n",
    "    \n",
    "        return 1/(1+sum_squares) \n",
    "    \n",
    "    # Returns pearson corelation coefficient for user1 and user2\n",
    "    # Score between -1 and 1 more score means more similarity b/w users \n",
    "    def pearson(self, rats, user1, user2):\n",
    "        # List of rated items\n",
    "        shared_items = {}\n",
    "        for item in rats[user1]:\n",
    "            if item in rats[user2]:\n",
    "                shared_items[item] = 1\n",
    "            \n",
    "        n = len(shared_items)\n",
    "        # if no common item, return 0\n",
    "        if n == 0: return 0\n",
    "    \n",
    "        # Add up all the ratings\n",
    "        sum1 = sum([rats[user1][item] for item in shared_items])\n",
    "        sum2 = sum([rats[user2][item] for item in shared_items])\n",
    "    \n",
    "        # Sum up all the squares of ratings\n",
    "        sum1Sq = sum([pow(rats[user1][item],2) for item in shared_items])\n",
    "        sum2Sq = sum([pow(rats[user2][item],2) for item in shared_items])\n",
    "    \n",
    "        # Sum up all the products\n",
    "        prodSum = sum([rats[user1][item]*rats[user2][item] for item in shared_items]) \n",
    "    \n",
    "        # Calculate pearson score\n",
    "        num = prodSum - (sum1*sum2/n)\n",
    "        temp = math.sqrt((sum1Sq - pow(sum1,2)/n) * (sum2Sq - pow(sum2,2)/n))\n",
    "        if temp == 0: return 0\n",
    "    \n",
    "        score = num/temp\n",
    "        return score\n",
    "    \n",
    "    \"\"\"\n",
    "    Computing similarity of one user to every other user in dataset.\n",
    "    This function will return a list of tuples with tuples containing similarity and id of the user\n",
    "\n",
    "    This function returns (n) most similar users where n is the number of movies we want our recommender to recommend,\n",
    "    (n) here can be increased to get even better results\n",
    "    \"\"\"\n",
    "    def getSimilarUsers(self, ratings, user, n=50):\n",
    "        sim = [(other, self.pearson(ratings, user, other)) for other in ratings if other!=user]\n",
    "    \n",
    "        # Sort list so that more similar users appear at top\n",
    "        sim = sorted(sim, key=itemgetter(1), reverse=True)\n",
    "    \n",
    "        # If first similarity is 0 means no similar user found, use euclid in such case\n",
    "        if sim[0][1] == 0:\n",
    "            sim = [(other, self.euclid(ratings, user, other)) for other in ratings if other!=user]\n",
    "    \n",
    "        # n denotes number of results to be returned\n",
    "        return sim[0:n]\n",
    "    \n",
    "    def getRecommendations(self, ratings, user, n=5):\n",
    "        totals = {}\n",
    "        simSums = {}\n",
    "        # Get a list of n most similar users\n",
    "        similar_users = self.getSimilarUsers(ratings, user, n*10)\n",
    "    \n",
    "        # For every similar user in similar_users rate the movie that user has'nt rated yet\n",
    "        for similar in similar_users:\n",
    "            other = similar[0]\n",
    "            sim = similar[1]\n",
    "            # if similarity less than 0, ignore\n",
    "            if(sim <= 0): continue\n",
    "            \n",
    "            for item in ratings[other]:\n",
    "                # only score movies user hasn't seen yet\n",
    "                if item not in ratings[user] or ratings[user][item] == 0:\n",
    "                    # similarity * other user rating\n",
    "                    totals.setdefault(item, 0)\n",
    "                    totals[item] += ratings[other][item]*sim\n",
    "                    # sum of similarities\n",
    "                    simSums.setdefault(item, 0)\n",
    "                    simSums[item] += sim\n",
    "    \n",
    "        # Normalize predicted ratings and store then as tuples in a list\n",
    "        rankings = [(item, total/simSums[item]) for item,total in totals.items()]\n",
    "        rankings = sorted(rankings, key=itemgetter(1), reverse=True)\n",
    "        return rankings[0:n]\n",
    "    \n",
    "    def predict(self, ratings, user, n=5):\n",
    "        book_data = gl.load_sframe(\"./book_data_clean/\")\n",
    "        ids_ratings = self.getRecommendations(ratings, user, n+50)\n",
    "        #list storing details of recommended books\n",
    "        list_of_books = []\n",
    "        list_of_ids = []\n",
    "    \n",
    "        # Serach a book via its id in book_data and append all its details along with rating to list_of_books\n",
    "        count = 0\n",
    "        for item in ids_ratings:\n",
    "            if count == n: break\n",
    "            # if book details not present in book_data, skip over to next until (n) books are appended to list\n",
    "            if item[0] not in book_data[\"book_id\"]: continue\n",
    "            \n",
    "            count += 1\n",
    "            book = book_data[book_data[\"book_id\"] == item[0]][0]\n",
    "            if item[1] > 10:\n",
    "                book[\"rating\"] = 10\n",
    "            else:\n",
    "                book[\"rating\"] = item[1]\n",
    "            # append id to another list and delete book id from dictionary\n",
    "            list_of_ids.append(book[\"book_id\"])\n",
    "            del(book[\"book_id\"])\n",
    "            del(book[\"rating\"])\n",
    "            list_of_books.append(book)\n",
    "        \n",
    "        return list_of_books[0:n], list_of_ids[0:n]\n",
    "    \n",
    "class CooccurModel:\n",
    "    \"\"\"\n",
    "    Using co_dict rather than matrix SFrame (constructed using co_dict), this will make computation much more efficient, \n",
    "    The score list store keys (in the corpus) and scores, on the basis of user's reading history\n",
    "\n",
    "    This cooccurrence dictionary is really sparse (5% of original data) hence I was able to find recommendation only \n",
    "    for 15 users out of 100 users(for which I tried to compute recommendation).\n",
    "    To increase the number of users which get recommendations, cooccur dictionary must be computed for other 95% data\n",
    "\n",
    "    This function will loops over all the users present in rating dictionary and will SKIP those user for which no \n",
    "    similar movies are found.\n",
    "    \n",
    "    n-> denotes the maximum number of books to be recommended to a user\n",
    "    \"\"\"\n",
    "    def predict(self, rating_dict, co_dict, userId=None, n=5):\n",
    "        recom_books = {}\n",
    "        \n",
    "        # Rating dictionary stores user as keys and another dictionary as values\n",
    "        # containing (book/corresponding ratings give by user) as key/value pair\n",
    "        if userId in rating_dict.keys():\n",
    "            user_rating = rating_dict[userId]\n",
    "            score = []\n",
    "            flag = 0\n",
    "    \n",
    "            # co_dict contains book_ids as keys and another dict as values containing\n",
    "            # book_ids and normalized similarity between those books(as key/value pair)\n",
    "            # Loop over all the books in the inventory\n",
    "            for bookId,book_sim in co_dict.items():\n",
    "                temp = 0\n",
    "            \n",
    "                # Loop over all the previouly rated book by a user and add the similarity b/w \n",
    "                # current book and EACH of the previously rated book.\n",
    "                # Compute final score by dividing total number of books user has already rated\n",
    "                for prev_rated in user_rating.keys(): \n",
    "                    if prev_rated in book_sim.keys():\n",
    "                        temp += book_sim[prev_rated]\n",
    "                    \n",
    "                if temp != 0:\n",
    "                    # To NORMALIZE score, divide score by total number of previouly rated books \n",
    "                    temp /= len(user_rating)\n",
    "                    flag = 1\n",
    "                    score.append((bookId, temp))\n",
    "            score = sorted(score, key=itemgetter(1), reverse=True)[0:n]\n",
    "    \n",
    "            if flag == 1:\n",
    "                recom_books.setdefault(userId, 0)\n",
    "                recom_books[userId] = score\n",
    "        return recom_books\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Function to get recommendations based on five different models.\n",
    "For a new usr with no previous history of interaction with books, set new_user to True, and pass age and location as \n",
    "function arguments.\n",
    "If the user has alredy interacted with books(i.e. previous history of user is available in data for user) then just pass \n",
    "the user_id which is stored in the data.\n",
    "\n",
    "(reg_max_search) variable denotes the number of books to be searched for recommendation it can be increased to search over \n",
    "upto 45000 books.\n",
    "Decrease reg_max_search value to lower computation time.\n",
    "sim_method can be chaged to euclid if similarity is to be calculated on the basis of euclidean distance.\n",
    "\"\"\"\n",
    "def suggest(new_user=False, loc=None, age=0, reg_max_search=3000, user_id=None, image_size=\"M\"):\n",
    "    \n",
    "    total_list_books = []\n",
    "    total_list_ids = []\n",
    "    if new_user == True:\n",
    "        # If new user recommend books only on the basis of popularity model and Regression model\n",
    "        # Recommend 3 books via Regression model and 2 books based on popularity model\n",
    "        reg_model = RegressionModel()\n",
    "        reg_books, reg_books_ids = reg_model.predict(loc, age, reg_max_search)\n",
    "        \n",
    "        pop_model = PopularityModel()\n",
    "        pop_books, pop_books_ids = pop_model.predict(train_data, item_data=book_data, user_id=\"user_id\", \n",
    "                                       item_id=\"book_id\", rating=\"ratings\")\n",
    "        # Append the books recommended by popularity and regression model to total list\n",
    "        for book in pop_books:\n",
    "            total_list_books.append(book)\n",
    "        for book in reg_books:\n",
    "            total_list_books.append(book)\n",
    "        for i in pop_books_ids:\n",
    "            total_list_ids.append(i)\n",
    "        for i in reg_books_ids:\n",
    "            total_list_ids.append(i)\n",
    "        \n",
    "    else:\n",
    "        # Changing the column names in book_data table for compatibility with all models \n",
    "        mod_book_data = book_data[[\"book_id\", \"title\", \"year\", \"author\", \"publisher\"]]\n",
    "        \n",
    "        \"\"\"\n",
    "        # If old user then predict on the basis of similarity, cooccurrence and Factorization model\n",
    "        \n",
    "        # Using ranking factorization model\n",
    "        # Selecting specific columns from book data\n",
    "        rank_fact_model = gl.load_model(\"./my_models/rank_imp_model/\")\n",
    "        fact_book_ids = list(rank_fact_model.recommend(users=[user_id])[\"book_id\"])[0:5]\n",
    "        for bookId in fact_book_ids:\n",
    "            if bookId in mod_book_data[\"book_id\"]:\n",
    "                info = mod_book_data[mod_book_data[\"book_id\"] == bookId][0]\n",
    "                total_list_ids.append(info[\"book_id\"])\n",
    "                del(info[\"book_id\"])\n",
    "                total_list_books.append(info)\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        # Using Similarity model\n",
    "        critics = np.load(\"rating_dictionary.npy\").item()\n",
    "        sim_model = SimilarityModel()\n",
    "        sim_books, sim_ids =  sim_model.predict(critics, user_id)\n",
    "        for book in sim_books:\n",
    "            total_list_books.append(book)\n",
    "        for i in sim_ids:\n",
    "            total_list_ids.append(i)\n",
    "        \n",
    "        # Using cooccurence matrix based model\n",
    "        # Loading required data\n",
    "        rating_dict = np.load(\"rating_dictionary.npy\").item()\n",
    "        co_dict = np.load(\"cooccurrence dict.npy\").item()\n",
    "        # To check if the returned dictionary is empty\n",
    "        flag = 0 \n",
    "        co_model = CooccurModel()\n",
    "        co_books = co_model.predict(rating_dict, co_dict, user_id)\n",
    "        if co_books:\n",
    "            co_books = co_books[user_id]\n",
    "            flag = 1\n",
    "        \n",
    "        if flag == 1:\n",
    "            for item in co_books:\n",
    "                bookId = item[0]\n",
    "                if bookId in mod_book_data[\"book_id\"]:\n",
    "                    book_info = mod_book_data[mod_book_data[\"book_id\"] == bookId][0]\n",
    "                    total_list_ids.append(book_info[\"book_id\"])\n",
    "                    del(book_info[\"book_id\"])\n",
    "                    total_list_books.append(book_info)\n",
    "                    \n",
    "        \n",
    "        \n",
    "        # Code to ensure that exactly five books are recommended to user\n",
    "        count = len(total_list_ids)\n",
    "        # If recommended books greater than 5 just strip\n",
    "        if  count > 5:\n",
    "            total_list_books = total_list_books[0:5]\n",
    "            total_list_ids = total_list_ids[0:5]\n",
    "        \n",
    "        # If recommended books less than 5 use regression model or popularity model to fill the gap\n",
    "        elif count < 5:\n",
    "            # total book to recommend is 5, counting the missing values\n",
    "            miss = 5 - count\n",
    "        \n",
    "            # Using regression model to fill missing values    \n",
    "            if user_id in user_data[\"user_id\"]:\n",
    "                user = user_data[\"user_id\"]\n",
    "                reg_model = RegressionModel()\n",
    "                reg_books, reg_books_ids = reg_model.predict(user[\"location\"], user[\"age\"], reg_max_search)\n",
    "                # appending reg_books and ids to total lists\n",
    "                total_list_books, total_list_ids = append(total_list_books, total_list_ids, \n",
    "                                                          reg_books, reg_books_ids, miss)\n",
    "                \n",
    "            # If regression model fails then use popularity model\n",
    "            else:\n",
    "                pop_model = PopularityModel()\n",
    "                pop_books, pop_books_ids = pop_model.predict(train_data, item_data=book_data, user_id=\"user_id\", \n",
    "                                       item_id=\"book_id\", rating=\"ratings\")\n",
    "                # appending pop_books and ids to total lists\n",
    "                total_list_books, total_list_ids = append(total_list_books, total_list_ids, \n",
    "                                                          pop_books, pop_books_ids, miss)\n",
    "                \n",
    "    show(total_list_books, total_list_ids, image_size)\n",
    "                        \n",
    "def append(total, totalids, books, bookids, miss):\n",
    "    temp = 0\n",
    "    for book in books:\n",
    "        if temp == miss: break\n",
    "        total.append(book)\n",
    "        temp += 1\n",
    "    temp = 0\n",
    "    for i in bookids:\n",
    "        if temp == miss: break\n",
    "        totalids.append(i)\n",
    "        temp += 1 \n",
    "    return total, totalids\n",
    "\n",
    "def show(books, bookids, size):\n",
    "    if size == \"M\":\n",
    "        dis = \"Image-URL-M\"\n",
    "    else:\n",
    "        dis = \"Image-URL-L\"\n",
    "    temp = -1\n",
    "    for i in bookids:\n",
    "        book = book_data[book_data[\"book_id\"] == i][0]\n",
    "        if i in book_data[\"book_id\"] and book[dis].startswith(\"http\"):\n",
    "            display(Image(url=book[dis]))\n",
    "        else:\n",
    "            print \"IMAGE FOR THIS BOOK IS NOT AVAILABLE\"\n",
    "        temp += 1   \n",
    "        print \"Title of Book :: \", books[temp][\"title\"]\n",
    "        print \"Author of Book :: \", books[temp][\"author\"]\n",
    "        print \"Year of Publication :: \", books[temp][\"year\"]\n",
    "        print \"Publisher :: \", books[temp][\"publisher\"]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://images.amazon.com/images/P/8427202962.01.MZZZZZZZ.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title of Book ::  El caso de los anónimos\n",
      "Author of Book ::  Agatha Christie\n",
      "Year of Publication ::  1983\n",
      "Publisher ::  Distribooks Inc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://images.amazon.com/images/P/1880909332.01.MZZZZZZZ.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title of Book ::  That's All Right, Mama: A Novel\n",
      "Author of Book ::  Gerald Duff\n",
      "Year of Publication ::  1995\n",
      "Publisher ::  Baskerville Publishers Inc.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://images.amazon.com/images/P/059035342X.01.MZZZZZZZ.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title of Book ::  Harry Potter and the Sorcerer's Stone (Harry Potter (Paperback))\n",
      "Author of Book ::  J. K. Rowling\n",
      "Year of Publication ::  1999\n",
      "Publisher ::  Arthur A. Levine Books\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://images.amazon.com/images/P/043935806X.01.MZZZZZZZ.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title of Book ::  Harry Potter and the Order of the Phoenix (Book 5)\n",
      "Author of Book ::  J. K. Rowling\n",
      "Year of Publication ::  2003\n",
      "Publisher ::  Scholastic\n"
     ]
    }
   ],
   "source": [
    "# Set image size to \"L\" to display large image or to \"S\" to display small image\n",
    "suggest(user_id=\"114078\", image_size=\"M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://images.amazon.com/images/P/059035342X.01.MZZZZZZZ.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title of Book ::  Harry Potter and the Sorcerer's Stone (Harry Potter (Paperback))\n",
      "Author of Book ::  J. K. Rowling\n",
      "Year of Publication ::  1999\n",
      "Publisher ::  Arthur A. Levine Books\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://images.amazon.com/images/P/043935806X.01.MZZZZZZZ.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title of Book ::  Harry Potter and the Order of the Phoenix (Book 5)\n",
      "Author of Book ::  J. K. Rowling\n",
      "Year of Publication ::  2003\n",
      "Publisher ::  Scholastic\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://images.amazon.com/images/P/0816029091.01.MZZZZZZZ.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title of Book ::  Encyclopedia of Gods: Over 2,500 Deities of the World\n",
      "Author of Book ::  Michael Jordan\n",
      "Year of Publication ::  1993\n",
      "Publisher ::  Facts on File\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://images.amazon.com/images/P/0312209711.01.MZZZZZZZ.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title of Book ::  Women on the Verge: Lesbian Tales of Power and Play (Stonewall Inn Editions)\n",
      "Author of Book ::  Susan Fox Rogers\n",
      "Year of Publication ::  1999\n",
      "Publisher ::  Stonewall Inn Editions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://images.amazon.com/images/P/053109474X.01.MZZZZZZZ.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title of Book ::  Big Squeak, Little Squeak\n",
      "Author of Book ::  Robert Kraus\n",
      "Year of Publication ::  1996\n",
      "Publisher ::  Orchard Books (NY)\n"
     ]
    }
   ],
   "source": [
    "suggest(new_user=True, loc=\"delhi, india\", age=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [alt-env]",
   "language": "python",
   "name": "Python [alt-env]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
